{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imbalanced Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/alexandraasinovsky/Downloads/talkingdata-adtracking-fraud-detection/train_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hh']  = pd.to_datetime(df.click_time).dt.hour.astype('uint8')\n",
    "X = df.drop(['click_time', 'attributed_time', 'is_attributed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['is_attributed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(sampling_strategy=0.5)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "warnings.filterwarnings('ignore')\n",
    "d_1 = {\"Model\": ['Logistic Regression','Support Vector Classification', 'Random Forest', 'Gradient Boosting'], \"Oversampling\": [], \"Undersampling\": []}\n",
    "d_2 = {\"Model\": ['Logistic Regression','Support Vector Classification', 'Random Forest', 'Gradient Boosting'],\"Oversampling\": [], \"Undersampling\": []}\n",
    "d_3 = {\"Model\": ['Logistic Regression','Support Vector Classification', 'Random Forest', 'Gradient Boosting'],\"Oversampling\": [], \"Undersampling\": []}\n",
    "d_4 = {\"Model\": ['Logistic Regression','Support Vector Classification', 'Random Forest', 'Gradient Boosting'],\"Oversampling\": [], \"Undersampling\": []}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using oversampling to find coefficients for logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, random_state=1)\n",
    "scores = {'f1': 'f1_micro', 'auc': 'roc_auc','precision': 'precision', 'recall': 'recall'}\n",
    "\n",
    "X_over, y_over = over.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, max_iter=1000).fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.19702804e-06,  4.27908285e-02, -3.44999269e-04,\n",
       "        -2.24833243e-03, -6.66263911e-03, -6.68023309e-02]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X, y, cv=10, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9978, 0.9978, 0.9978, 0.9977, 0.9977, 0.9977, 0.9977, 0.9976,\n",
       "       0.9977, 0.9977])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = cross_val_score(clf, X, y, scoring='f1_micro', cv=cv)\n",
    "auc = cross_val_score(clf, X, y, scoring='roc_auc', cv=cv)\n",
    "pres = cross_val_score(clf, X, y, scoring='precision', cv=cv)\n",
    "rec = cross_val_score(clf, X, y, scoring='recall', cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_m = {'f1': np.mean(f1['test_score']) , 'test_auc': np.mean(auc['test_score']) , 'test_precision': np.mean(pres['test_score']) , 'test_recall': np.mean(rec['test_score']) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997715</td>\n",
       "      <td>0.624699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1  test_auc  test_precision  test_recall\n",
       "0  0.997715  0.624699             0.0          0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame(scores_m, index=[0])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>hh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87540</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>497</td>\n",
       "      <td>2017-11-07 09:30:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105560</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>259</td>\n",
       "      <td>2017-11-07 13:40:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101424</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>212</td>\n",
       "      <td>2017-11-07 18:05:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94584</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>477</td>\n",
       "      <td>2017-11-07 04:58:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68413</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>2017-11-09 09:00:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>124883</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>122</td>\n",
       "      <td>2017-11-09 13:25:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>85150</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>244</td>\n",
       "      <td>2017-11-07 11:25:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>18839</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-11-08 11:38:42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>114276</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>245</td>\n",
       "      <td>2017-11-08 17:55:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>119349</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>401</td>\n",
       "      <td>2017-11-07 14:32:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ip  app  device  os  channel           click_time attributed_time  \\\n",
       "0       87540   12       1  13      497  2017-11-07 09:30:38             NaN   \n",
       "1      105560   25       1  17      259  2017-11-07 13:40:27             NaN   \n",
       "2      101424   12       1  19      212  2017-11-07 18:05:24             NaN   \n",
       "3       94584   13       1  13      477  2017-11-07 04:58:08             NaN   \n",
       "4       68413   12       1   1      178  2017-11-09 09:00:09             NaN   \n",
       "...       ...  ...     ...  ..      ...                  ...             ...   \n",
       "99995  124883   11       1  19      122  2017-11-09 13:25:41             NaN   \n",
       "99996   85150    9       1  13      244  2017-11-07 11:25:43             NaN   \n",
       "99997   18839    3       1  13       19  2017-11-08 11:38:42             NaN   \n",
       "99998  114276   15       1  12      245  2017-11-08 17:55:21             NaN   \n",
       "99999  119349   14       1  15      401  2017-11-07 14:32:27             NaN   \n",
       "\n",
       "       is_attributed  hh  \n",
       "0                  0   9  \n",
       "1                  0  13  \n",
       "2                  0  18  \n",
       "3                  0   4  \n",
       "4                  0   9  \n",
       "...              ...  ..  \n",
       "99995              0  13  \n",
       "99996              0  11  \n",
       "99997              0  11  \n",
       "99998              0  17  \n",
       "99999              0  14  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>hh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>3804</td>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>459</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60498</th>\n",
       "      <td>169013</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>259</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53227</th>\n",
       "      <td>75007</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>237</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21333</th>\n",
       "      <td>25676</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>442</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>5299</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>280</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26543</th>\n",
       "      <td>43827</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85764</th>\n",
       "      <td>44067</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>278</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87585</th>\n",
       "      <td>70347</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32519</th>\n",
       "      <td>5314</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>140</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18831</th>\n",
       "      <td>23524</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ip  app  os  channel  hh\n",
       "3582     3804   64  18      459   9\n",
       "60498  169013   25  19      259  14\n",
       "53227   75007    2  10      237   7\n",
       "21333   25676   14  13      442  12\n",
       "3885     5299    3  13      280   9\n",
       "...       ...  ...  ..      ...  ..\n",
       "26543   43827    9  10      134   0\n",
       "85764   44067   15   3      278   8\n",
       "87585   70347   23  19      153   1\n",
       "32519    5314   15  19      140  17\n",
       "18831   23524    3  19      205   6\n",
       "\n",
       "[25000 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_lr_o = [('o', over),  ('m', LogisticRegression(solver = 'lbfgs', max_iter=1000))]\n",
    "pipeline_lr_o = Pipeline(steps=steps_lr_o)\n",
    "\n",
    "\n",
    "\n",
    "scores_lr_o = cross_validate(pipeline_lr_o, X, y, scoring=scores, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Logistic regressiion with oversampling: 0.86402, auc: 0.81220, precision: 0.01057, recall: 0.61937\n"
     ]
    }
   ],
   "source": [
    "score_lr_f1_o = np.mean(scores_lr_o['test_f1'])\n",
    "d_1[\"Oversampling\"].append(score_lr_f1_o)\n",
    "\n",
    "score_lr_auc_o = np.mean(scores_lr_o['test_auc'])\n",
    "d_2[\"Oversampling\"].append(score_lr_auc_o)\n",
    "\n",
    "score_lr_prec_o = np.mean(scores_lr_o['test_precision'])\n",
    "d_3[\"Oversampling\"].append(score_lr_prec_o)\n",
    "\n",
    "score_lr_rec_o = np.mean(scores_lr_o['test_recall'])\n",
    "d_4[\"Oversampling\"].append(score_lr_rec_o)\n",
    "\n",
    "s = 'F1 Score of Logistic regressiion with oversampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_lr_f1_o , score_lr_auc_o, score_lr_prec_o, score_lr_rec_o)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Logistic regressiion with undersampling: 0.85976, auc: 0.81059, precision: 0.01006, recall: 0.61623\n"
     ]
    }
   ],
   "source": [
    "steps_lr_u = [('u', under),  ('m', LogisticRegression(solver = 'lbfgs', max_iter=1000))]\n",
    "pipeline_lr_u = Pipeline(steps=steps_lr_u)\n",
    "\n",
    "scores_lr_u = cross_validate(pipeline_lr_u, X, y, scoring=scores, cv=cv)\n",
    "\n",
    "score_lr_f1_u = np.mean(scores_lr_u['test_f1'])\n",
    "d_1[\"Undersampling\"].append(score_lr_f1_u)\n",
    "\n",
    "score_lr_auc_u = np.mean(scores_lr_u['test_auc'])\n",
    "d_2[\"Undersampling\"].append(np.mean(score_lr_auc_u))\n",
    "\n",
    "score_lr_prec_u = np.mean(scores_lr_u['test_precision'])\n",
    "d_3[\"Undersampling\"].append(score_lr_prec_u)\n",
    "\n",
    "score_lr_rec_u = np.mean(scores_lr_u['test_recall'])\n",
    "d_4[\"Undersampling\"].append(score_lr_rec_u)\n",
    "\n",
    "s = 'F1 Score of Logistic regressiion with undersampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_lr_f1_u , score_lr_auc_u, score_lr_prec_u, score_lr_rec_u)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of SVC with oversampling: 0.70024, auc: 0.71246, precision: 0.01704, recall: 0.56648\n"
     ]
    }
   ],
   "source": [
    "steps_svc_o = [('o', over),  ('m', SGDClassifier(max_iter=1000, tol=1e-3))]\n",
    "pipeline_svc_o = Pipeline(steps=steps_svc_o)\n",
    "\n",
    "scores_svc_o = cross_validate(pipeline_svc_o, X, y, scoring=scores, cv=cv)\n",
    "\n",
    "score_svc_f1_o = np.mean(scores_svc_o['test_f1'])\n",
    "d_1[\"Oversampling\"].append(score_svc_f1_o)\n",
    "\n",
    "score_svc_auc_o = np.mean(scores_svc_o['test_auc'])\n",
    "d_2[\"Oversampling\"].append(score_svc_auc_o)\n",
    "\n",
    "score_svc_prec_o = np.mean(scores_svc_o['test_precision'])\n",
    "d_3[\"Oversampling\"].append(score_svc_prec_o)\n",
    "\n",
    "score_svc_rec_o = np.mean(scores_svc_o['test_recall'])\n",
    "d_4[\"Oversampling\"].append(score_svc_rec_o)\n",
    "\n",
    "s = 'F1 Score of SVC with oversampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_svc_f1_o , score_svc_auc_o, score_svc_prec_o, score_svc_rec_o)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of SVC with undersampling: 0.53028, auc: 0.51833, precision: 0.00122, recall: 0.48644\n"
     ]
    }
   ],
   "source": [
    "steps_svc_u = [('u', under),  ('m', SGDClassifier(max_iter=1000, tol=1e-3))]\n",
    "pipeline_svc_u = Pipeline(steps=steps_svc_u)\n",
    "\n",
    "\n",
    "scores_svc_u = cross_validate(pipeline_svc_u, X, y, scoring=scores, cv=cv)\n",
    "\n",
    "score_svc_f1_u = np.mean(scores_svc_u['test_f1'])\n",
    "d_1[\"Undersampling\"].append(score_svc_f1_u)\n",
    "\n",
    "score_svc_auc_u = np.mean(scores_svc_u['test_auc'])\n",
    "d_2[\"Undersampling\"].append(score_svc_auc_u)\n",
    "\n",
    "score_svc_prec_u = np.mean(scores_svc_u['test_precision'])\n",
    "d_3[\"Undersampling\"].append(score_svc_prec_u)\n",
    "\n",
    "score_svc_rec_u = np.mean(scores_svc_u['test_recall'])\n",
    "d_4[\"Undersampling\"].append(score_svc_rec_u)\n",
    "\n",
    "s = 'F1 Score of SVC with undersampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_svc_f1_u , score_svc_auc_u, score_svc_prec_u, score_svc_rec_u)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Random Forest with oversampling: 0.99772, auc: 0.83579, precision: 0.50084, recall: 0.30022\n"
     ]
    }
   ],
   "source": [
    "steps_rf_o = [('o', over),  ('m', RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0))]\n",
    "pipeline_rf_o = Pipeline(steps=steps_rf_o)\n",
    "\n",
    "scores_rf_o = cross_validate(pipeline_rf_o, X, y, scoring=scores, cv=cv)\n",
    "\n",
    "score_rf_f1_o = np.mean(scores_rf_o['test_f1'])\n",
    "d_1[\"Oversampling\"].append(score_rf_f1_o)\n",
    "\n",
    "score_rf_auc_o = np.mean(scores_rf_o['test_auc'])\n",
    "d_2[\"Oversampling\"].append(score_rf_auc_o)\n",
    "\n",
    "score_rf_prec_o = np.mean(scores_rf_o['test_precision'])\n",
    "d_3[\"Oversampling\"].append(score_rf_prec_o)\n",
    "\n",
    "score_rf_rec_o = np.mean(scores_rf_o['test_recall'])\n",
    "d_4[\"Oversampling\"].append(score_rf_rec_o)\n",
    "\n",
    "s = 'F1 Score of Random Forest with oversampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_rf_f1_o , score_rf_auc_o, score_rf_prec_o, score_rf_rec_o)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Random Forest with undersampling: 0.96414, auc: 0.83579, precision: 0.50084, recall: 0.30022\n"
     ]
    }
   ],
   "source": [
    "steps_rf_u = [('u', under),  ('m', RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0))]\n",
    "pipeline_rf_u = Pipeline(steps=steps_rf_u)\n",
    "\n",
    "scores_rf_u = cross_validate(pipeline_rf_u, X, y, scoring=scores, cv=cv)\n",
    "\n",
    "score_rf_f1_u = np.mean(scores_rf_u['test_f1'])\n",
    "d_1[\"Undersampling\"].append(score_rf_f1_u)\n",
    "\n",
    "score_rf_auc_u = np.mean(scores_rf_o['test_auc'])\n",
    "d_2[\"Undersampling\"].append(score_rf_auc_u)\n",
    "\n",
    "score_rf_prec_u = np.mean(scores_rf_o['test_precision'])\n",
    "d_3[\"Undersampling\"].append(score_rf_prec_u)\n",
    "\n",
    "score_rf_rec_u = np.mean(scores_rf_o['test_recall'])\n",
    "d_4[\"Undersampling\"].append(score_rf_rec_u)\n",
    "\n",
    "s = 'F1 Score of Random Forest with undersampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_rf_f1_u , score_rf_auc_u, score_rf_prec_u, score_rf_rec_u)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Gradient Boosting with oversampling: 0.97285, auc: 0.95857, precision: 0.07302, recall: 0.86362\n"
     ]
    }
   ],
   "source": [
    "steps_gb_o = [('o', over),  ('m', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))]\n",
    "pipeline_gb_o = Pipeline(steps=steps_gb_o)\n",
    "\n",
    "scores_gb_o = cross_validate(pipeline_gb_o, X, y, scoring=scores, cv=cv)\n",
    "\n",
    "score_gb_f1_o = np.mean(scores_gb_o['test_f1'])\n",
    "d_1[\"Oversampling\"].append(score_gb_f1_o)\n",
    "\n",
    "score_gb_auc_o = np.mean(scores_gb_o['test_auc'])\n",
    "d_2[\"Oversampling\"].append(score_rf_auc_o)\n",
    "\n",
    "score_gb_prec_o = np.mean(scores_gb_o['test_precision'])\n",
    "d_3[\"Oversampling\"].append(score_gb_prec_o)\n",
    "\n",
    "score_gb_rec_o = np.mean(scores_gb_o['test_recall'])\n",
    "d_4[\"Oversampling\"].append(score_gb_rec_o)\n",
    "\n",
    "s = 'F1 Score of Gradient Boosting with oversampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_gb_f1_o , score_gb_auc_o, score_gb_prec_o, score_gb_rec_o)\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score of Gradient Boosting with undersampling: 0.95262, auc: 0.94435, precision: 0.04422, recall: 0.86490\n"
     ]
    }
   ],
   "source": [
    "steps_gb_u = [('u', under),  ('m', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0))]\n",
    "pipeline_gb_u = Pipeline(steps=steps_gb_u)\n",
    "\n",
    "scores_gb_u = cross_validate(pipeline_gb_u, X, y, scoring=scores, cv=cv)\n",
    "\n",
    "score_gb_f1_u = np.mean(scores_gb_u['test_f1'])\n",
    "d_1[\"Undersampling\"].append(score_gb_f1_u)\n",
    "\n",
    "score_gb_auc_u = np.mean(scores_gb_u['test_auc'])\n",
    "d_2[\"Undersampling\"].append(score_gb_auc_u)\n",
    "\n",
    "score_gb_prec_u = np.mean(scores_gb_u['test_precision'])\n",
    "d_3[\"Undersampling\"].append(score_gb_prec_u)\n",
    "\n",
    "score_gb_rec_u = np.mean(scores_gb_u['test_recall'])\n",
    "d_4[\"Undersampling\"].append(score_gb_rec_u)\n",
    "\n",
    "s = 'F1 Score of Gradient Boosting with undersampling: %.5f, auc: %.5f, precision: %.5f, recall: %.5f' % (score_gb_f1_u , score_gb_auc_u, score_gb_prec_u, score_gb_rec_u)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Oversampling</th>\n",
       "      <th>Undersampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.864016</td>\n",
       "      <td>0.859763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classification</td>\n",
       "      <td>0.700239</td>\n",
       "      <td>0.530277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.997719</td>\n",
       "      <td>0.964141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.972854</td>\n",
       "      <td>0.952616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Oversampling  Undersampling\n",
       "0            Logistic Regression      0.864016       0.859763\n",
       "1  Support Vector Classification      0.700239       0.530277\n",
       "2                  Random Forest      0.997719       0.964141\n",
       "3              Gradient Boosting      0.972854       0.952616"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1\n",
    "df_1 = pd.DataFrame().from_dict(d_1)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Oversampling</th>\n",
       "      <th>Undersampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.812201</td>\n",
       "      <td>0.810588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classification</td>\n",
       "      <td>0.712464</td>\n",
       "      <td>0.518329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>0.835786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>0.944345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Oversampling  Undersampling\n",
       "0            Logistic Regression      0.812201       0.810588\n",
       "1  Support Vector Classification      0.712464       0.518329\n",
       "2                  Random Forest      0.835786       0.835786\n",
       "3              Gradient Boosting      0.835786       0.944345"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# auc\n",
    "df_2 = pd.DataFrame().from_dict(d_2)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Oversampling</th>\n",
       "      <th>Undersampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.010055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classification</td>\n",
       "      <td>0.017043</td>\n",
       "      <td>0.001220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.500843</td>\n",
       "      <td>0.500843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.073018</td>\n",
       "      <td>0.044221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Oversampling  Undersampling\n",
       "0            Logistic Regression      0.010572       0.010055\n",
       "1  Support Vector Classification      0.017043       0.001220\n",
       "2                  Random Forest      0.500843       0.500843\n",
       "3              Gradient Boosting      0.073018       0.044221"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "df_3 = pd.DataFrame().from_dict(d_3)\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Oversampling</th>\n",
       "      <th>Undersampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.619368</td>\n",
       "      <td>0.616225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classification</td>\n",
       "      <td>0.566482</td>\n",
       "      <td>0.486443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.300217</td>\n",
       "      <td>0.300217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.863617</td>\n",
       "      <td>0.864901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Oversampling  Undersampling\n",
       "0            Logistic Regression      0.619368       0.616225\n",
       "1  Support Vector Classification      0.566482       0.486443\n",
       "2                  Random Forest      0.300217       0.300217\n",
       "3              Gradient Boosting      0.863617       0.864901"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "df_4 = pd.DataFrame().from_dict(d_4)\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Random forest perform the best where it comes to precision with oversampling and undersampling, but recall is best in Gradient Boosting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
